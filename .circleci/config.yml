version: 2.1

base_defaults: &base_defaults
    resource_class: xlarge
    working_directory: /chronon

executors:
    docker_baseimg_executor:
        resource_class: xlarge
        working_directory: /chronon
        docker:
            - image: houpy0829/chronon-ci:base--f87f50dc520f7a73894ae024eb78bd305d5b08e2
    docker_baseimg_executor_xxlarge:
      resource_class: 2xlarge
      working_directory: /chronon
      docker:
        - image: houpy0829/chronon-ci:base--f87f50dc520f7a73894ae024eb78bd305d5b08e2

jobs:
    "Pull Docker Image":
        <<: *base_defaults
        docker:
            - image: docker:17.05.0-ce-git
        steps:
            - setup_remote_docker:
                docker_layer_caching: true
            - checkout
            - run:
                name: Pull existing docker image
                command: |
                    set +o pipefail
                    docker pull houpy0829/chronon-ci:base--f87f50dc520f7a73894ae024eb78bd305d5b08e2 || true

    "Scala 12 -- Spark 3 Tests":
        executor: docker_baseimg_executor_xxlarge
        steps:
            - checkout
            - run:
                  name: Run Spark 3.1.1 tests
                  shell: /bin/bash -leuxo pipefail
                  command: |
                      conda activate chronon_py
                      # Increase if we see OOM.
                      export SBT_OPTS="-XX:+CMSClassUnloadingEnabled -XX:MaxPermSize=4G -Xmx4G -Xms2G"
                      sbt "++ 2.12.12 test"
            - store_test_results:
                  path: /chronon/spark/target/test-reports
            - store_test_results:
                  path: /chronon/aggregator/target/test-reports
            - run:
                  name: Compress spark-warehouse
                  command: |
                    cd /tmp/ && tar -czvf spark-warehouse.tar.gz chronon/spark-warehouse
                  when: on_fail
            - store_artifacts:
                  path: /tmp/spark-warehouse.tar.gz
                  destination: spark_warehouse.tar.gz
                  when: on_fail

    "Scala 13 -- Tests":
        executor: docker_baseimg_executor
        steps:
            - checkout
            - run:
                  name: Run Scala 13 tests
                  shell: /bin/bash -leuxo pipefail
                  command: |
                      conda activate chronon_py
                      # Increase if we see OOM.
                      export SBT_OPTS="-XX:+CMSClassUnloadingEnabled -XX:MaxPermSize=8G -Xmx8G -Xms4G"
                      sbt "++ 2.13.6 test"
            - store_test_results:
                  path: /chronon/spark/target/test-reports
            - store_test_results:
                  path: /chronon/aggregator/target/test-reports
            - run:
                  name: Compress spark-warehouse
                  command: |
                    cd /tmp/ && tar -czvf spark-warehouse.tar.gz chronon/spark-warehouse
                  when: on_fail
            - store_artifacts:
                  path: /tmp/spark-warehouse.tar.gz
                  destination: spark_warehouse.tar.gz
                  when: on_fail

    "Scala 11 -- Compile":
      executor: docker_baseimg_executor
      steps:
        - checkout
        - run:
            name: Compile Scala 11
            shell: /bin/bash -leuxo pipefail
            command: |
              conda activate chronon_py
              # Increase if we see OOM.
              export SBT_OPTS="-XX:+CMSClassUnloadingEnabled -XX:MaxPermSize=4G -Xmx4G -Xms2G"
              sbt "++ 2.11.12 compile"

    "Chronon Python Lint":
        executor: docker_baseimg_executor
        steps:
            - checkout
            - run:
                  name: Run Chronon Python lint
                  shell: /bin/bash -leuxo pipefail
                  command: |
                      conda activate chronon_py
                      cd /chronon/api/py/ai/chronon
                      pip install importlib-metadata==4.11.4 #Install importlib-metadata < 5
                      flake8 --extend-ignore=W605,Q000,F631,E203

    "Chronon Python Tests":
        executor: docker_baseimg_executor
        steps:
            - checkout
            - run:
                  name: Run Chronon Python tests
                  shell: /bin/bash -leuxo pipefail
                  command: |
                    conda activate chronon_py
                    pushd /chronon/api/
                    thrift --gen py -out /chronon/api/py/ai/chronon\
                       /chronon/api/thrift/api.thrift                 # Generate thrift files
                    cd /chronon/                                      # Go to Python module
                    pip install -r api/py/requirements/dev.txt        # Install latest requirements
                    tox                                               # Run tests
                    popd
            - store_artifacts:
                  path: /chronon/api/py/htmlcov

    "Scalafmt Check":
        executor: docker_baseimg_executor
        steps:
            - checkout
            - run:
                  name: Run ScalafmtCheck
                  shell: /bin/bash -leuxo pipefail
                  command: |
                      conda activate chronon_py
                      sbt +scalafmtCheck
    # run these separately as we need a isolated JVM to not have Spark session settings interfere with other runs
    # long term goal is to refactor the current testing spark session builder and avoid adding new single test to CI
    "Scala 13 -- Iceberg Format Tests":
      executor: docker_baseimg_executor
      steps:
        - checkout
        - run:
            name: Run Scala 13 tests for Iceberg format
            environment:
              format_test: iceberg
            shell: /bin/bash -leuxo pipefail
            command: |
              conda activate chronon_py
              # Increase if we see OOM.
              export SBT_OPTS="-XX:+CMSClassUnloadingEnabled -XX:MaxPermSize=4G -Xmx4G -Xms2G"
              sbt ';project spark_embedded; ++ 2.13.6; testOnly ai.chronon.spark.test.TableUtilsFormatTest'
        - store_test_results:
            path: /chronon/spark/target/test-reports
        - store_test_results:
            path: /chronon/aggregator/target/test-reports
        - run:
            name: Compress spark-warehouse
            command: |
              cd /tmp/ && tar -czvf spark-warehouse.tar.gz chronon/spark-warehouse
            when: on_fail
        - store_artifacts:
            path: /tmp/spark-warehouse.tar.gz
            destination: spark_warehouse.tar.gz
            when: on_fail
    "Scala 13 -- Iceberg Table Utils Tests":
      executor: docker_baseimg_executor
      steps:
        - checkout
        - run:
            name: Run Scala 13 tests for Iceberg Table Utils
            environment:
              format_test: iceberg
            shell: /bin/bash -leuxo pipefail
            command: |
              conda activate chronon_py
              # Increase if we see OOM.
              export SBT_OPTS="-XX:+CMSClassUnloadingEnabled -XX:MaxPermSize=4G -Xmx4G -Xms2G"
              sbt ';project spark_embedded; ++ 2.13.6; testOnly ai.chronon.spark.test.TableUtilsTest'
        - store_test_results:
            path: /chronon/spark/target/test-reports
        - store_test_results:
            path: /chronon/aggregator/target/test-reports
        - run:
            name: Compress spark-warehouse
            command: |
              cd /tmp/ && tar -czvf spark-warehouse.tar.gz chronon/spark-warehouse
            when: on_fail
        - store_artifacts:
            path: /tmp/spark-warehouse.tar.gz
            destination: spark_warehouse.tar.gz
            when: on_fail

    # Job for Main branch builds (Read/Write cache)
    "Bazel Tests - Main Branch":
        executor: docker_baseimg_executor_xxlarge
        environment:
            BuildBuddyAPIKey: ${BuildBuddyAPIKey}
        steps:
            - checkout
            - run:
                name: Run Bazel Setup
                command: |
                    # Add Bazel GPG key and repository
                    curl -fsSL https://bazel.build/bazel-release.pub.gpg | gpg --dearmor | sudo tee /usr/share/keyrings/bazel-archive-keyring.gpg > /dev/null
                    echo "deb [arch=amd64 signed-by=/usr/share/keyrings/bazel-archive-keyring.gpg] https://storage.googleapis.com/bazel-apt stable jdk1.8" | sudo tee /etc/apt/sources.list.d/bazel.list
                    # Update package list and install specific Bazel version
                    sudo apt update
                    sudo apt install -y bazel-6.4.0
                    # Set up bazel-6.4.0 as the default bazel command
                    sudo update-alternatives --install /usr/bin/bazel bazel /usr/bin/bazel-6.4.0 100
            - run:
                name: Setup permissions
                command: |
                    sudo mkdir -p /root/.cache/bazel
                    useradd --create-home --shell /bin/bash nonroot
                    chown -R nonroot:nonroot /chronon
                    chown -R nonroot:nonroot /root/.cache/bazel # Give access to the bazel cache
            - run:
                name: ðŸš€ Run Bazel Tests (Read/Write Cache)
                shell: /bin/bash -leuxo pipefail
                command: |
                    export JAVA_OPTS="-XX:+CMSClassUnloadingEnabled -XX:MaxPermSize=4G -Xmx4G -Xms2G"
                    sudo -E -u nonroot -H -s /bin/bash -c "
                        bazel version && 
                        bazel build //... --config=main --remote_header=x-buildbuddy-api-key=$BuildBuddyAPIKey && 
                        bazel test //... --config=main --config=ci --remote_header=x-buildbuddy-api-key=$BuildBuddyAPIKey"
            - store_test_results:
                path: bazel-testlogs
            - store_artifacts:
                path: bazel-testlogs
                destination: bazel-test-logs
                when: on_fail

    # Job for PR builds (Read-Only cache)
    "Bazel Tests - PR":
        executor: docker_baseimg_executor_xxlarge
        environment:
            BuildBuddyAPIKey: ${BuildBuddyAPIKey}
        steps:
            - checkout
            - run:
                name: Run Bazel Setup
                command: |
                    # Add Bazel GPG key and repository
                    curl -fsSL https://bazel.build/bazel-release.pub.gpg | gpg --dearmor | sudo tee /usr/share/keyrings/bazel-archive-keyring.gpg > /dev/null
                    echo "deb [arch=amd64 signed-by=/usr/share/keyrings/bazel-archive-keyring.gpg] https://storage.googleapis.com/bazel-apt stable jdk1.8" | sudo tee /etc/apt/sources.list.d/bazel.list
                    # Update package list and install specific Bazel version
                    sudo apt update
                    sudo apt install -y bazel-6.4.0
                    # Set up bazel-6.4.0 as the default bazel command
                    sudo update-alternatives --install /usr/bin/bazel bazel /usr/bin/bazel-6.4.0 100
            - run:
                name: Setup permissions
                command: |
                    sudo mkdir -p /root/.cache/bazel
                    useradd --create-home --shell /bin/bash nonroot
                    chown -R nonroot:nonroot /chronon
                    chown -R nonroot:nonroot /root/.cache/bazel # Give access to the bazel cache
            - run:
                name: Run Bazel Tests
                shell: /bin/bash -leuxo pipefail
                command: |
                    export JAVA_OPTS="-XX:+CMSClassUnloadingEnabled -XX:MaxPermSize=4G -Xmx4G -Xms2G"
                    sudo -E -u nonroot -H -s /bin/bash -c "
                        bazel version && 
                        bazel build //... --config=main --remote_header=x-buildbuddy-api-key=\${BuildBuddyAPIKey} && 
                        bazel test //... --config=main --config=ci --remote_header=x-buildbuddy-api-key=\${BuildBuddyAPIKey}"
            - store_test_results:
                path: bazel-testlogs
            - store_artifacts:
                path: bazel-testlogs
                destination: bazel-test-logs
                when: on_fail

workflows:
    build_test_deploy:
        jobs:
            - "Pull Docker Image"
            - "Scala 11 -- Compile":
                requires:
                  - "Pull Docker Image"
            - "Scala 12 -- Spark 3 Tests":
                  requires:
                      - "Pull Docker Image"
            - "Scala 13 -- Tests":
                  requires:
                      - "Pull Docker Image"
            - "Scalafmt Check":
                  requires:
                      - "Pull Docker Image"
            - "Chronon Python Tests":
                  requires:
                      - "Pull Docker Image"
            - "Chronon Python Lint":
                  requires:
                      - "Pull Docker Image"
            - "Scala 13 -- Iceberg Format Tests":
                  requires:
                      - "Pull Docker Image"
            - "Scala 13 -- Iceberg Table Utils Tests":
                  requires:
                      - "Pull Docker Image"
            - "Bazel Tests - Main Branch":
                  filters:
                      branches:
                          only:
                              - main
            - "Bazel Tests - PR":
                  filters:
                      branches:
                          ignore:
                              - main