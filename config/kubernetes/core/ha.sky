# DO NOT EDIT: http://go/vendor-skycfg
"""
Plugins for making Kubernetes configurations highly available
"""

load("config/kubernetes/helpers/context.sky", "is_isolated_deploy", "get_name")
load("config/kubernetes/helpers/proto_or_yaml.sky", "TopologySpreadConstraint")
load("config/kubernetes/meta/metadata.sky", "render_selector")
load("config/kubernetes/plugins/types.sky", "pod_plugin")
load("config/kubernetes/helpers/warning.sky", "warn")


def spread_across_zones(selected_zones=()):
    """Spread pods across availability zones.

    NOTE: We suspect this plugin has no effect; the kubernetes scheduler by
    default will try to balance pods across availability zones with a skew of 5.

    Args:
        selected_zones: A tuple of zones in which the pod may be scheduled, for use
            if you have some locality constraint to meet. If left empty the pods may
            be scheduled in any zone.

    Returns:
        A plugin that makes the service highly available in the event of an AZ failure.
    """
    return pod_plugin(_add_anti_affinity_to_pod, selected_zones=selected_zones)

def _add_anti_affinity_to_pod(ctx, arguments, pod_def):
    selected_zones = arguments.selected_zones
    pod_def["affinity"]["highly_available"] = True
    pod_def["affinity"]["highly_available_zones"] = selected_zones

def require_node_balance(max_skew=1):
    """Require that a workload's pods be balanced across Nodes.

    The scheduler will refuse to assign pods to nodes if sufficient balance cannot be acheived
    and allow Karpenter to spin up a new Node to meet the constraint.
    NOTE: Do not use this plugin directly. Instead, set `set_require_node_balance_with_skew=1` in deployment() which internally uses this plugin.

    Args:
        max_skew: The maximum amount of skew to allow, as defined by topology
            spread constraints: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/#spread-constraints-for-pods.
            Must be > 0.
    """
    if max_skew <= 0:
        fail("max_skew must be positive")
    return pod_plugin(_add_topology_spreading_to_pod, max_skew=max_skew, topology_key="kubernetes.io/hostname", strict_constraint=True, by_service=False)

def require_node_balance_by_henson_service(max_skew=1):
    """Require that a workload's pods be balanced across nodes by Henson service name (rather than deployment name)

    The scheduler will refuse to assign pods to nodes if sufficient balance cannot be acheived
    and allow Karpenter to spin up a new Node to meet the constraint.

    Args:
        max_skew: The maximum amount of skew to allow, as defined by topology
            spread constraints: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/#spread-constraints-for-pods.
            Must be > 0.
    """
    if max_skew <= 0:
        fail("max_skew must be positive")
    return pod_plugin(_add_topology_spreading_to_pod, max_skew=max_skew, topology_key="kubernetes.io/hostname", strict_constraint=True, by_service=True)

def prefer_node_balance(max_skew=1):
    """Prefer that a workload's pods be balanced across Nodes.

    The scheduler will safely fallback to assigning pods to nodes if sufficient balance cannot be acheived.

    Args:
        max_skew: The maximum amount of skew to allow, as defined by topology
            spread constraints: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/#spread-constraints-for-pods.
            Must be > 0.
    """
    if max_skew <= 0:
        fail("max_skew must be positive")
    return pod_plugin(_add_topology_spreading_to_pod, max_skew=max_skew, topology_key="kubernetes.io/hostname", strict_constraint=False, by_service=False)

def require_zone_balance(max_skew=1):
    """Require that a workload's pods be balanced across availability zones.

    The scheduler will refuse to assign pods to nodes if sufficient balance cannot be acheived.
    NOTE: Do not use this plugin directly. Instead, set `set_require_zone_balance_with_skew=1` in deployment() which internally uses this plugin.

    Args:
        max_skew: The maximum amount of skew to allow, as defined by topology
            spread constraints: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/#spread-constraints-for-pods.
            Must be > 0.
    """
    if max_skew <= 0:
        fail("max_skew must be positive")
    return pod_plugin(_add_topology_spreading_to_pod, max_skew=max_skew, topology_key="topology.kubernetes.io/zone", strict_constraint=True, by_service=False)

def prefer_zone_balance(max_skew=1):
    """Prefer that a workload's pods be balanced across availability zones.

    The scheduler will safely fallback to assigning pods to nodes if sufficient balance cannot be acheived.

    Args:
        max_skew: The maximum amount of skew to allow, as defined by topology
            spread constraints: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/#spread-constraints-for-pods.
            Must be > 0.
    """
    if max_skew <= 0:
        fail("max_skew must be positive")
    return pod_plugin(_add_topology_spreading_to_pod, max_skew=max_skew, topology_key="topology.kubernetes.io/zone", strict_constraint=False, by_service=False)

def _add_topology_spreading_to_pod(ctx, arguments, pod_def):
    constraints = pod_def.get("topology_spreading", [])
    constraints.append(arguments)
    pod_def["topology_spreading"] = constraints

def render_topology_spreading(ctx, pod):
    """
    Produces a list of topology spread constraints for this pod.

    Args:
        ctx: Henson context.
        pod: The pod definition struct.

    Returns:
        A list of TopologySpreadConstraints to apply to the pod.
    """

    # Skip setting topology spreading for isolated deployements as they're always single replicas
    if is_isolated_deploy(ctx):
        warn(ctx, "skipping applying topology spreading plugin due to isolated deployments")
        return None

    plugins = getattr(pod, "topology_spreading", None)
    if plugins == None:
        return None
    constraints = []
    for plugin in plugins:
        constraints += _render_topology_spreading(ctx, plugin, pod)
    return constraints

def _render_topology_spreading(ctx, plugin, pod):

    selector = render_selector(ctx, pod.resource["metadata"])
    # Copy the selectors over so that we dont unintentionally mutate the
    # original selector.
    selector_copy = json.unmarshal(json.marshal(selector))
    # Spread pods by Henson service name instead of deployment name
    # if requested by the caller
    selector_match_labels = selector_copy.get("matchLabels", {})
    if plugin.by_service and selector_match_labels.get("stripe.io/service-name"):
        selector_match_labels.pop("stripe.io/service-name")
        selector_match_labels["stripe.io/henson-service"] = get_name(ctx)

    # Include the current henson-git-commit in the selector to address
    # https://github.com/kubernetes/kubernetes/issues/98215.
    if hasattr(pod.resource["metadata"], "henson_git_commit"):
        if selector_copy.get("matchLabels"):
            selector_copy["matchLabels"]["stripe.io/henson-git-commit"] = pod.resource["metadata"].henson_git_commit

    when_unsatisfiable = "DoNotSchedule"
    if not plugin.strict_constraint:
        when_unsatisfiable = "ScheduleAnyway"

    return [TopologySpreadConstraint(
        ctx,
        labelSelector = selector_copy,
        maxSkew = plugin.max_skew,
        topologyKey = plugin.topology_key,
        whenUnsatisfiable = when_unsatisfiable,
    )]
